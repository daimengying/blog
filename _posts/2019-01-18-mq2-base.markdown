---
layout: post
title:  "mq如何保证高可用，解决重复消费、数据丢失问题和顺序性问题"
categories: 消息队列
tags:Java高阶面试
author: mydai
description: Java面试突击集锦（二）：消息队列之复杂性问题解决。
---


### 一、如何保证消息队列的高可用
##### 1. RabbitMQ的高可用性
rabbitmq有三种模式：**单机模式，普通集群模式，镜像集群模式**
- 普通集群模式：多台机器部署，每个机器放一个rabbitmq实例，但是创建的queue只会放在一个rabbitmq实例上，每个实例同步queue的元数据。如果消费时连的是其他实例，那个实例会从queue所在实例拉取数据。这就会导致拉取数据的开销，如果那个放queue的实例宕机了，那么其他实例就无法从那个实例拉取，即便开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，但得等这个实例恢复了，然后才可以继续从这个queue拉取数据，这就没什么高可用可言，主要是提供吞吐量，让集群中多个节点来服务某个queue的读写操作。
- 镜像集群模式：queue的元数据和消息都会存放在多个实例，每次写消息就自动同步到多个queue实例里。这样任何一个机器宕机，其他机器都可以顶上，但是性能开销太大，消息同步导致网络带宽压力和消耗很重，另外，没有扩展性可言，如果queue负载很重，加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue。此时，需要开启镜像集群模式，在rabbit管理控制台新增一个策略，将数据同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了
##### 2. kafka的高可用性
kafka架构：多个broker组成，每个broker是一个节点；创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。<br/>
它是一个分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。<br/><br/>
kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。<br/><br/>
kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到吉他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。kafka会均匀的将一个partition的所有replica分布在不同的机器上，从而提高容错性。<br/>
如果某个broker宕机了也没事，它上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。<br/><br/>
写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。<br/>
消费的时候，只会从leader去读，但是只有当消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。


### 二、如何保证消息不被重复消费
kafka重复消费的情况：
kafka有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，下次重启时，从上次消费到的offset来继续消费。但是offset没来得及提交就重启，这部分会再次消费一次。<br/><br/>
怎么保证消息队列消费的幂等性：
- 比如数据写库，可以先根据主键查一下，如果这数据都有了，就update
- 比如写redis，那没问题，因为每次都是set，天然幂等性
- 如果不是上面两个场景，那做的稍微复杂一点，需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后消费到了后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，就处理，然后这个id写redis。如果消费过了，那就别处理了，保证别重复处理相同的消息即可。
- 还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据

### 三、如何保证消息的可靠性传输（如何处理消息丢失的问题）
丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了
##### 1. rabbitmq
- 生产者弄丢了数据：<br/><br/>
生产者将数据发送到rabbitmq的时候，因为网络或者其他问题，半路给搞丢了。<br/><br/>
此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是rabbitmq事务机会降低吞吐量，因为太耗性能。<br/><br/>
所以一般是开启<span style="color:red">confirm模式</span>，在生产者那里设置开启confirm模式后，每次写消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发<br/><br/>
事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。<br/><br/>
- rabbitmq丢失数据：<br/>
开启rabbitmq的持久化。设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。<br/>
而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。<br/><br/>
- 消费端弄丢了数据<br/><br/>
消费的时候，刚消费到，还没处理，结果进程挂了，比如重启，此时rabbitmq认为消费过了，这数据就丢了。<br/><br/>
用rabbitmq提供的ack机制，简单来说，就是关闭rabbitmq自动ack，可以通过一个api来调用，然后每次代码里确保处理完的时候，再程序里ack一把。这样的话，如果还没处理完，就没有ack，那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。

##### 2. kafka
- 消费端弄丢了数据<br/><br/>
唯一可能就是消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢了。<br/><br/>
只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。<br/><br/>
- kafka弄丢了数据<br/><br/>
kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，中间这部分数据就丢失了。<br/><br/>
所以此时一般是要求起码设置如下4个参数：<br/>
(1)给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本<br/>
(2)在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower<br/>
(3)在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了<br/>
(4)在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了<br/><br/>
- 生产者会不会弄丢数据<br/><br/>
如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

### 三、如何保证消息的顺序性
##### 1. rabbitmq
拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理
##### 2. kafka
写入一个partition中的数据一定是有序的，生产者在写的时候 ，可以指定一个key，比如指定订单id作为key，这个订单相关数据一定会被分发到一个partition中去。消费者从partition中取出数据的时候也一定是有序的，把每个数据放入对应的一个内存队列，一个partition中有几条相关数据就用几个内存队列，消费者开启多个线程，每个线程处理一个内存队列。

